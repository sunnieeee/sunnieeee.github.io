---
layout: post
title: "Machine Learning"
description: "机器学习笔记"
categories: [Machine Learning]
tags: [code,Machine Learning]
redirect_from:
  - /2018/08/29/
---

>  机器学习笔记

[TOC]

# 机器学习实践应用学习笔记

Created 2018.08.29 by Sunnie; Last modified: 2018.08.29-V1.0.6

Contact :[1249053233@qq.com](mailto:1249053233@qq.com)

Copyleft! 2018 Yuqing Cao. Some rights reserved.

------

## Chapter1----机器学习概述

### 一、机器学习流程

1. 场景解析：把应用场景抽象成逻辑问题，对应上机器学习中的常用场景，把业务逻辑和算法进行匹配

2. 数据预处理：减少量纲，减少噪声数据对训练数据集的影响

3. 特征工程：对应用场景选取正确好用的特征来评判一个结果的好坏

   参考https://www.cnblogs.com/wkslearner/p/8933685.html

4. 模型训练：经过预处理和特征工程后的训练数据进入算法中，生成模型，模型用于处理预测集数据来生产预测结果

5. 模型评估：机器学习算法得到的一般是一个模型，对该模型成熟度评估

6. 离线/在线服务：离线服务训练新的数据，得到新的离线模型，通过在线服务提供实时预测查询服务

### 二、数据

1. 结构化数据：日志类数据结构，可用二维表结构（excel）来显示。机器学习算法通常只支持结构化数据。

   包含特征和目标列两个重要概念：

   - 特称（feature）：数据所描述对象的属性
   - 目标列（label）：每一份数据的打标结果

2. 半结构化数据：按一定结构储存却不是二维的数据库行存储形态的数据，或者二维结构表中部分数值型部分文本型数据混用。

3. 非结构化数据：图像语音文本等不能以矩阵的结构储存的数据。

小注：机器学习算法对结构化数据处理较好，另外两类要转化成结构化数据处理。

### 三、算法分类

1. **监督学习**：每个进入算法的训练数据样本都有对应的期望目标值，机器学习的过程是特征值和目标队列映射的过程，由于目标列大部分需要人工打标，所以获得目标值成本较高。

   常用于回归及分类场景，算法：

| 场景   | 算法                            |
| :--- | :---------------------------- |
| 分类算法 | K近邻、朴素贝叶斯、决策树、随机森林、GBDT、支持向量机 |
| 回归算法 | 逻辑回归、线性回归                     |

2. **无监督学习**：不依赖打标数据的机器学习算法，没有目标队列，常用于聚类场景问题，比对不同样本之间的距离关系。

| 聚类算法            | 推荐算法  |
| :-------------- | :---- |
| K-Means、 DBSCAN | 协同过滤等 |

3. 半监督学习：用部分样本打标的样本训练模型——标签传播算法
4. 强化学习：系统与外界不断的交互，获得外界的反馈，然后决定自身的行为，用于需要不断推理的场景——隐马尔可夫算法

### 四、过拟合问题

机器学习算法过度学习了训练集数据，导致这套模型在训练的时候过度接近于训练集的特征，缺乏鲁棒性，对其他需要预测的数据集不适用。

1.过拟合出现的原因：

- 训练数据样本单一：训练样本要尽可能全面覆盖所有数据类型
- 训练样本噪声数据干扰过大：模型忽略输入输出之间的关系
- 模型太过于复杂：模型参数过多

2.预防和解决方法：

- 训练和建立模型时从相对简单的模型开始
- 数据的采样要尽可能覆盖全部数据种类，数据要经过清洗后再进行算法训练
- 利用数学手段预防过拟合，在算法中添加惩罚函数来预防过拟合，参考正则化L1、L2规范

### 五、结果评估

模型好坏的评估指标：

1. 精确率/召回率/F1值
2. ROC曲线/AUC



## Chapter2----场景解析

数据挖掘的第一阶段，对应用场景和数据集分析，搭建合适的机器学习算法 

### 一、数据探查

1. 数据量的大小是否足够，数据量越大效果越好，我们要保证数据量可以实现算法收敛或者模型最优。维度越多需要的数据了也越大。
2. 数据是否有缺失值或者乱码，若有需要进行ETL（数据清洗）操作。
3. 字段类型是否符合算法支持要求，例如文本分析要求字符型，逻辑回归需要数值型的等。
4. 是否含有目标队列，来选择有监督学习还是无监督学习。

### 二、场景抽象

通过已有的数据挖掘出可以应用的业务场景，如商品推荐，疾病预测，人物关系挖掘。

### 三、算法选择

1. 确定算法范围流程：数据种类➡是否存在目标队列➡根据实际业务场景选择
2. 多算法尝试：根据第一步确定的范围尝试符合要求的算法，选择最好的
3. 多视角分析：从其他角度分析，如鲁棒性、复杂度、调参及优化成本



## Chapter3----数据预处理

数据挖掘的第二阶段，采样、去噪、归一化、数据过滤

### 一、采样

从数据集中挑选样本数据

1. 随机采样：分为有放回采样和无放回采样
2. 系统采样：又称为等距采样，是无放回抽样
3. 分层采样：先将数据分成若干个类别，再从每一层内随机抽取一定数量样本

### 二、归一化

一种简化计算的方式，可以加快算法的收敛速度。

### 三、去噪

例如3σ原则。

### 四、数据过滤

去掉一组数据里对结果没有意义的字段。



## Chapter4----特征工程

特征工程是数据挖掘流程中的核心部分 

### 一、特征抽象

将源数据抽象成算法可以理解的数据，源数据可能是数字，或者是模糊的文字信息。

1. 时间戳：来自于系统日志的时间戳通常为年-月-日的格式，不便于计算，往往选定一天作为基准做差分，将日期变为相对时间。
2. 二值类问题：譬如男女表示成0、1。
3. 多值有序问题： 譬如根据轻重程度不同如轻度疼痛、中度疼痛、重度疼痛表示成0、1、2、3。
4. 多值无序问题（信息阉割）：对于无法排序的多值信息，根据应用场景选择与应用场景最有关的特性表达，忽略其他信息。
5. 多值无序问题（One-hot编码）：根据预先设定好的规则把每个信息编码然后组合在一起，变成长度一定的一串数列计算。
6. 文本类型：根据词长，词性，TF-IDF值等提取特征。
7. 图像或语音处理：转化为矩阵结构。

### 二、特征重要性评估

对每个特征的重要性（权重）进行评估并排序。

方法：

1. 回归模型系数判断法：回归模型通过中每个特征（变量）前面的系数可以推出每个特征的重要性。

2. 信息熵判断法：信息熵是一个信息量抽象的概念，对信息量的研究专门有一门学科叫做信息论。在1948年，信息论的鼻祖香农提出了“信息熵”的概念，真正地把信息这样一个抽象的东西量化。

   信息熵的具体计算方法：在信源中考虑的不是某一单个符号发生的不确定性，而是要考虑这个信源所有可能发生情况的平均不确定性。若信源符号有n种可能 $U_1,U_2,U_3,U_4 ...$ ，每种可能对应的概率分别为 $P_1,P_2,P_3,P_4...$，且各种符号的出现彼此独立。信源的平均不确定性应当为单个符号不确定性$-logP_i$ 的统计平均值 $E$，即 $H(U)=E[-logP_i]=-\sum_{i=1}^{n}P_i logP_i$ 。

   通过计算信息增益（目标列的熵减去特征列的熵）表示某个特征的重要性

### 三、特征衍生

利用现有特征进行某种组合，生成新的具有含义的特征。

例如淘宝购物的系统日志，通过用户点击和购买记录可以推断出用户的购物频率和点击购买率以及和时间序列的关系。对商品的特性可以从热度、购买次数、消耗频率、季节特性、二次购买率等描述。 

### 四、特征降维

减少输入矩阵的维度。

1. 降维目的：

   - 确保变量间的相互独立性，去除加在不同字段上的相同冗余信息
   - 减少计算量，工业中采集的矩阵维度很大，带来巨大的运算压力
   - 去噪：把对结果没有意义或者意义非常小的字段去掉，较少特征评估阶段的工作量

2. 降维方法：

   - 主成分分析（PCA）：通过线性映射把高维数据映射到低维空间中，尽可能保证投影维度上数据方差最大
   - 线性判别式分析（LDA）：使模式样本在子空间里有最大的类间距离和最小类内距离
   - 局部线性嵌入（LLE）：非线性降维算法，特点是降维之后能保持数据的流形结构

3. 主成分分析（PCA）：

   - 基本思路：

     把坐标轴旋转到数据方差最大方向（即找到数据主轴方向），把源数据的最大方差方向变为新坐标系的一个坐标轴，一直重复这个操作来降低维度。

     对于一个特征，它的方差表示了它数据的集中程度；对于两个特征（子集），他们之间的协方差表示了他们之间的正负相关程度；对于多个特征，求他们之间的协方差矩阵，矩阵之中的每个值是两两特征之间的协方差，表达了这两个特征的相关程度。

     复习特征向量和特征值的概念：特征向量乘某个向量（协方差矩阵），方向不变，长度变化，变化多少由特征值决定。所以特征值可以表示某个特征（某一维度）对整体的影响程度，或者说是方差，信息量越大。

     所以PCA的过程就是求出协方差矩阵的所有特征向量和特征值，把特征值按大小排序，保留前N维的特征向量，就是将矩阵降到N维。该方法（PCA降维）也广泛用于图像处理中（人脸识别）。



## Chapter5----机器学习算法—常规算法

### 一、分类算法

1. K近邻（KNN）：

   KNN是监督学习分类算法，主要用来解决分类问题，需要有打标数据，KNN通过考虑与目标距离最近的K个点所属的集合（已打标数据）中那个类别的点数量最占优势来判断目标属于哪一类。

2. 朴素贝叶斯（NBM）：

   以条件概率为基础的监督学习算法，在假设条件-所有特征的条件之间相互独立。通过计算概率公式来判断某件事情发生的概率或者分类归属情况。公式为$P(A|B)=\frac{P(B|A)P(A)}{P(B)}$ 

3. 逻辑回归（LR）：

   一种广义线性回归分析模型，监督学习算法，逻辑回归最终得到一组特征的系数，每个特征有一个系数相乘。用sigmoid函数将结果控制在[0,1]实现二分类，通过最优化算法找到这个函数（分类的界限）。

4. 支持向量机（SVM，Support Vector Machine）：

   有监督的分类算法，找到能区分特征空间最大间隔的分类器，把问题转化为一个凸二次规划问题的求解。对于线性可分问题，与之前的逻辑回归实现一样；非线性可分问题的数据难以用一条曲线把数据分类（数据交织在一起），可以利用核函数的方法将数据映射到高纬度空间中去，在高维空间中把数据分类。特点：是一种基于小样本学习的算法，引入了最大边界思想，提供了一种处理非线性可分场景的思路，鲁棒性好。

5. 随机森林：

   由多个决策树组成的分类器，监督学习。每个决策树是一个弱分类器，最终的结果由这些弱分类器投票决定。每个决策树的特征是通过抽样生成的每棵树的训练数据也是抽样生成的，随机森林通过对特征和训练样本的随机采样训练，生成多个决策树（森林）从而实现预测。

### 二、聚类算法

聚类是把一堆数据中有相似属性的一组数据归为一类，与分类问题不同，分类问题一般解决有监督学习场景，数据已经打标，而聚类解决的是无监督学习的场景，只将数据分开而不做定义和判断。

1. K-means算法（根据距离聚类）：

   是一种无监督的，基于距离聚类的机器学习算法，要在计算之前确定聚类簇心的数量即K值，表示最终需要生成K个簇；然后通过代码随机生成初始数据簇中心点，对第一次质心做第一次遍历，将所有数据做第一次分类，显然随机生成的中心效果并不理想，K-means是通过不断迭代来调优效果的。第二次遍历会利用第一次聚类结果每个类别的中心的点，以此类推，每次聚类利用上一次聚类的两个质心。

2. DBScan算法（根据密度聚类）：

   需要给两个参数，半径和中心邻域内最少点的数量（表示密度）。不需要预设聚类的K值，还可以过滤噪音，DBScan的距离用欧式距离来计算。首先取一个没有被访问过的点，判断这个点是否是核心点（参见核心点的定义），如果是核心点，那么这个点就跟附近Eps范围内的所有点形成一个簇，递归处理该簇中其他没有被标记的点，扩大这个簇的范围，找到更多彼此密度相连的点，从而对目前的簇进行扩展；如果这个点不是核心点，就把这个点标记成噪音。

### 三、回归算法

回归和分类的区别：如果预测的变量是离散的，我们称其为分类，如果预测变量是连续的，我们称其为回归。从数学角度看，回归就是拟合出贴近实际数据点的曲线，通常被用来预测 未来数据的走向。

回归方程为多元变量函数，然后通过最优化算法优化函数中每个变量（特征）的系数，如梯度下降算法或者最小二乘法。

### 四、文本分析算法

1. 分词算法-Hmm

   将句子按照每个词的意义进行分割，对英文文本而言英文本身就是用空格来分隔词的，不需要再次分词，但是中文词语之间不具备天然分隔符，故需要对语意分析。

   分词可分为三种方法：

   - 机械分词：查询词库（涵盖所有中文词语），将文章中与词库匹配的词语挑出来，这样效率低下，而且存在语义歧义的问题。可通过其他方法优化。
   - 统计分词：一种简单的基于概率的分词算法，从海量文本中找出同时出现频率很高的几个字，这几个字可能就会组成一个词语，对新词语的感知能力强（网络新词）。
   - 机器学习分词：对结果的预测过程，通过计算每种分词可能性大概率大小来进行分词并得到最终结果。如隐马尔可夫模型（HMM）和条件随机场（CRF）算法。

   HMM作为统计模型，被广泛应用于语音识别，行为识别，文字识别以及故障诊断等领域，（参见<https://www.cnblogs.com/mdumpling/p/7747000.html>）

2. TF-IDF（自动对文章打标算法）

   词频-逆向文件频率（TF-IDF），是一种用于信息检索和数据挖掘的加权技术，一方面出现频率高的词最能代表文章意义，另一方面要把多篇文章放一起比较，找出每篇文章中的独特词语，在这篇文章中出现多而在其他文章出现少（排除介词代词等）。满足这两个条件的词才有代表性才能作为标签来代表文章。

3. LDA（主题模型算法）

   隐含狄利克雷分布（LDA）计算的是每个文章的主题，可以将文章的主题作为标签做相关性推荐，也可以用于文章基于主题的分类。

### 五、推荐类算法（淘宝的个性化推荐系统）

协同过滤（CF）算法，是一种基于类别的推荐算法，核心理念就是找出爱好相同的人或者属性相似的物。

- 基于人的推荐（UCF）：从全量数据集中找出哪些人是有共同偏好的针对人群之间的相似偏好进行推荐。
- 基于物品的推荐（ICF）：从物品的角度找到相似度高的商品进行推荐。

### 六、关系图算法

针对输入数据源呈图状（网状、关系网）结构的算法，算法的核心是community，可以通过算法挖掘关系网络中的主要成分，预测行车轨迹的最短路径，判断社交网络中彼此的亲密程度，金融行业中的风险管控等。

1. 标签传播算法（LPA）

   基于图数据的半监督算法，LPA的基本原理是在一个庞大的数据集合中，已知其中一部分的标记数据，然后通过数据间彼此的联系最后得到全部数据的标记结果。

2. 迪杰斯特拉（Dijkstra）最短路径算法

   两端点间可能有多条连接线路可以选择时，找出两点间的最短链路。



## Chapter6----机器学习算法—深度学习

### 一、深度学习概述

从算法网络深度的角度来看可以把机器学习算法分成浅层学习算法和深度学习算法。

- 浅层学习：就是隐藏层（输入数据在隐藏层被抽象成特征信息）较少的神经网络，如支持向量机和逻辑回归，浅层学习都是监督学习，通过求解梯度找到函数最优化搜索的方向，但是深度学习中隐藏层较多，不能再用浅层学习的思想。

  在推荐系统或者一些分类场景下的应用（特征不复杂）浅层学习往往能达到很好的效果，但是对于图片、语音、文本这种特征复杂的数据就需要深度学习算法。

- 深度学习：是由输入层、隐藏层和输出层三部分组成，隐藏层可以包含很多层，单纯使用浅层算法的模型优化思想来优化每一层的参数会对模型的精度有不利影响，所以在模型训练方面深度学习采用反向传播算法（又称BP算法），是一种监督学习算法，BP算法的核心思想是求导的链式法则，常被用来求解神经网络中的最优化问题，用链式法则对每一层迭代计算梯度，但是BP算法对前方隐藏层的影响是逐渐衰减的，所以需要用其他手段优化BP算法。

注：在浅层学习中特征是由手工提取生成的，但是深度学习可以通过算法自动构建特征，将特征映射到不同维度的空间中，如自动编码算法可以逐层抽象并且构建特征。

### 二、深度学习常见结构（DNN，CNN，RNN）

1. 深度神经网络（DNN）：特指层次比较多的神经网络。（上一章的那些算法也是神经网络，只是层次浅）
2. 卷积神经网络（CNN）：是一种特殊的深度学习结构，通过卷积来解决空间上一些复杂特征的问题，例如图像识别中，如果对像素上每一个的RGB都做特征训练（每个隐藏层都做），计算量会非常大，而CNN利用卷积核作为权重向下传导中介，降低了每一层计算复杂度。
   - 卷积：通过对图片矩阵用卷积核进行一次卷积后，输入矩阵维数降低了，做到的参数的压缩，可以把训练流程简化，通过卷积核也能学习出对输入数据的特征描述，整个CNN学习的过程就是在确定卷积核的具体数值。
   - 下采样：对图像进行自抽样，减少数据的处理量，是有效的信息尽可能保留。
   - 全连接：将之前两步生成的各种特征图谱信息汇总并综合判断，返回希望得到的结果。
3. 循环神经网络（RNN）：环状的深度神经网络，常用来解决时序行为的问题。RNN在隐藏层的输出可以作为自身的输入，参数可以环状传导。对文本分析和语音识别来说，下一个时间产生的文本会受前一时刻文本的影响，时间维度上是彼此关联的，所以RNN的环状特点适用于这种时序空间的联系。RNN的结构中每一个隐藏层计算时都会考虑前一个隐藏层的参数以及当前的输入。目前RNN广泛应用于自然语言处理和股票预测等时间相关的场景下。



## Chapter7----常用机器学习工具

### 一、工具介绍

1. 单机版：两款软件 SPSS 和 RStudio（R语言）
2. 开源分布式：Spark MLib 和 **Tensorflow**
3. 企业级云机器学习工具：亚马逊AWS ML 阿里云机器学习PAI

## Chapter8----场景应用实战

由于比较无聊，就没写笔记

## Chapter9----知识图谱

工具推荐protege



## Further reading

- [THE MNIST DATABASEof handwritten digits](http://yann.lecun.com/exdb/mnist/) 手写字图片数据集 
- [The CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) 场景解析图片数据集 
- [书中源码《机器学习实践应用》/ 李博 著. 人民邮电出版社](https://github.com/jimenbian/GarvinBook)
- 作者CSDN博客：[李博Garvin的专栏](https://blog.csdn.net/buptgshengod)

------

## License

[![CC0](http://i.creativecommons.org/p/zero/1.0/88x31.png)](http://creativecommons.org/publicdomain/zero/1.0/)

